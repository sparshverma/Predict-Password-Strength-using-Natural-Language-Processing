# -*- coding: utf-8 -*-
"""predict_password_strength.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HF4u9Fiy4Dw6c0mL0F7NYvKKqw6UKgsW
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sqlite3

"""# Read data from SQL Database"""

con = sqlite3.connect(r"password_data.sqlite")

data = pd.read_sql_query("SELECT * FROM Users" , con)

data.shape

data.head(4)

"""# Doing basic data cleaning"""

data.columns

data.drop(["index"] , axis=1 , inplace=True)

data.head(4)

data.duplicated().sum()

data.isnull().any()

data.isnull().any().sum()

data.dtypes

data["strength"]

data["strength"].unique()

"""# Performing Semantics Analysis"""

data.columns

data["password"]

data["password"][0]

type(data["password"][0])

data["password"].str.isnumeric()

data[data["password"].str.isnumeric()]

data[data["password"].str.isnumeric()].shape

data[data["password"].str.isupper()]

data[data["password"].str.isalpha()]

data[data["password"].str.isalpha()].shape

data[data["password"].str.isalnum()]

data[data["password"].str.isalnum()].shape

data[data["password"].str.istitle()]

data["password"]

import string

string.punctuation

def find_semantics(row):
  for char in row:
    if char in string.punctuation:
      return 1
    else:
      pass

data["password"].apply(find_semantics)==1

data[data["password"].apply(find_semantics)==1]

"""# Applying Feature Engineering"""

data['password'][0]

len(data['password'][0])

data["length"] = data['password'].str.len()

data.head(4)

"""# Now we are going to Normalize frequency by dividing each small character value by the total length for the object."""

def freq_lowercase(row):
  return len([char for char in row if char.islower()])/len(row)

def freq_uppercase(row):
  return len([char for char in row if char.isupper()])/len(row)

def freq_numerical_case(row):
  return len([char for char in row if char.isdigit()])/len(row)

data["lowercase_freq"] = np.round(data["password"].apply(freq_lowercase) , 3)
data["uppercase_freq"] = np.round(data["password"].apply(freq_uppercase) , 3)
data["digit_freq"] = np.round(data["password"].apply(freq_numerical_case) , 3)

data.head(2)

def freq_special_case(row):
  special_chars = []
  for char in row:
    if not char.isalpha() and not char.isdigit():
      special_chars.append(char)
  return len(special_chars)

data["special_char_freq"] = np.round(data["password"].apply(freq_special_case) , 3)

data.head(4)

data["special_char_freq"] = data["special_char_freq"]/data["length"]

data.head(4)

"""# Performing Descriptive Statistics"""

data.columns

data[['length' , 'strength']].groupby(['strength']).agg(["min","max","mean","median"])

cols = ['length', 'lowercase_freq', 'uppercase_freq', 'digit_freq', 'special_char_freq']

for col in cols:
  print(col)
  print(data[[col , 'strength']].groupby(['strength']).agg(["min","max","mean","median"]))
  print('\n')

fig , ((ax1 , ax2) , (ax3 , ax4) , (ax5 , ax6)) = plt.subplots(3 , 2 , figsize=(15,7))

sns.boxplot(x="strength" , y='length' , hue="strength" , ax=ax1 , data=data)
sns.boxplot(x="strength" , y='lowercase_freq' , hue="strength" , ax=ax2, data=data)
sns.boxplot(x="strength" , y='uppercase_freq' , hue="strength" , ax=ax3, data=data)
sns.boxplot(x="strength" , y='digit_freq' , hue="strength" , ax=ax4, data=data)
sns.boxplot(x="strength" , y='special_char_freq' , hue="strength" , ax=ax5, data=data)

plt.subplots_adjust(hspace=0.6)

"""# Figuring out important features"""

def get_dist(data , feature):
  plt.figure(figsize=(10,8))
  plt.subplot(1,2,1)

  sns.violinplot(x='strength' , y=feature , data=data)
  plt.subplot(1,2,2)

  sns.distplot(data[data['strength']==0][feature], color="red" , label="0" , hist=False)
  sns.distplot(data[data['strength']==1][feature], color="blue", label="1", hist=False)
  sns.distplot(data[data['strength']==2][feature], color="orange", label="2", hist=False)
  plt.legend()
  plt.show()

import warnings
from warnings import filterwarnings
filterwarnings('ignore')

get_dist(data , "length")

get_dist(data , 'lowercase_freq')

get_dist(data , 'uppercase_freq')

get_dist(data , 'digit_freq')

get_dist(data , 'special_char_freq')

"""# Applying TF_IDF on data"""

data.head(4)

dataframe = data.sample(frac=1)

dataframe

x = list(dataframe["password"])

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(analyzer="char")

X = vectorizer.fit_transform(x)

X.shape

dataframe["password"].shape

X

X.toarray()

X.toarray()[0]

dataframe["password"]

len(vectorizer.get_feature_names_out())

vectorizer.get_feature_names_out()

df2 = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())

df2

"""# Applying Machine Learing algorithm"""

dataframe.columns

df2["length"] = dataframe['length']
df2["lowercase_freq"] = dataframe['lowercase_freq']

df2

y = dataframe["strength"]

# spliting the data into train and test
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(df2, y, test_size=0.20)

X_train.shape

y_train.shape

from sklearn.linear_model import LogisticRegression

clf = LogisticRegression(multi_class="multinomial")

clf.fit(X_train , y_train)

y_pred = clf.predict(X_test)

y_pred

from collections import Counter

Counter(y_pred)

"""# Doing prediction on sample data (user-entered input)"""

password = "@123abcd"

sample_array = np.array([password])

sample_metrics = vectorizer.transform(sample_array)

sample_metrics.toarray()

sample_metrics.toarray().shape

len(password)

[char for char in password if char.islower()]

len([char for char in password if char.islower()])/len(password)

np.append(sample_metrics.toarray(), (8, 0.5)).shape

np.append(sample_metrics.toarray(), (8, 0.5)).reshape(1,101)

np.append(sample_metrics.toarray(), (8, 0.5)).reshape(1,101).shape

new_matrics = np.append(sample_metrics.toarray(), (8, 0.5)).reshape(1,101)

clf.predict(new_matrics)

def predict():
    password = input("Enter a password : ")
    sample_array = np.array([password])
    sample_matrix = vectorizer.transform(sample_array)

    length_pass = len(password)
    length_normalised_lowercase = len([char for char in password if char.islower()])/len(password)

    new_matrix2 = np.append(sample_matrix.toarray() , (length_pass , length_normalised_lowercase)).reshape(1,101)
    result = clf.predict(new_matrix2)

    if result == 0 :
        return "Password is weak"
    elif result == 1 :
        return "Password is normal"
    else:
        return "password is strong"

predict()

"""# Model evaluation"""

from sklearn.metrics import confusion_matrix , accuracy_score , classification_report

accuracy_score(y_test , y_pred)

confusion_matrix(y_test , y_pred)

# creating report of the model
print(classification_report(y_test , y_pred))

